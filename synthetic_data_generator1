import pandas as pd
from io import StringIO
from langchain.chat_models import ChatGroq
from langchain.schema import AIMessage

# Load input data
file_path = "input_data.xlsx"  # Change to your actual file
df = pd.read_csv(file_path) if file_path.endswith('.csv') else pd.read_excel(file_path)

# Analyze Schema Dynamically
schema = {}
for col in df.columns:
    dtype = str(df[col].dtype)
    unique_values = df[col].nunique()
    
    if dtype == 'object':
        sample_values = df[col].dropna().unique()[:5].tolist()
        schema[col] = {"type": "categorical", "samples": sample_values}
    elif dtype in ['int64', 'float64']:
        schema[col] = {
            "type": "numeric",
            "min": df[col].min(),
            "max": df[col].max(),
            "mean": df[col].mean(),
            "std": df[col].std()
        }

print("Schema Analysis Completed:", schema)

# Initialize LLM (Groq with LLaMA 3.1)
llm = ChatGroq(model="llama3-70b-8192", temperature=0.7, api_key="your_groq_api_key")

# Dynamically construct prompt based on schema
while True:
    prompt = "Generate synthetic tabular data in CSV format based on the following schema:\n\n"

    for col, details in schema.items():
        if details["type"] == "categorical":
            prompt += f"- {col}: Categorical, sample values: {details['samples']}\n"
        elif details["type"] == "numeric":
            prompt += (f"- {col}: Numeric, Range: ({details['min']} to {details['max']}), "
                       f"Mean: {details['mean']}, Std Dev: {details['std']}\n")

    prompt += "\nEnsure the synthetic data statistically matches the input dataset. Output only CSV data."

    # Invoke LLM
    response = llm.invoke(prompt)

    # Extract LLM output and convert to DataFrame
    synthetic_data = response.content.strip()
    synthetic_df = pd.read_csv(StringIO(synthetic_data))

    # Compute drift by comparing input and generated data
    input_profile = df.describe(include="all")
    synthetic_profile = synthetic_df.describe(include="all")

    drift_detected = False

    for col in df.columns:
        if col in synthetic_df.columns:
            # Compare mean, std for numerical columns
            if df[col].dtype in ['int64', 'float64'] and synthetic_df[col].dtype in ['int64', 'float64']:
                mean_diff = abs(input_profile.loc['mean', col] - synthetic_profile.loc['mean', col])
                std_diff = abs(input_profile.loc['std', col] - synthetic_profile.loc['std', col])
                
                if mean_diff > 0.1 * input_profile.loc['mean', col] or std_diff > 0.1 * input_profile.loc['std', col]:
                    drift_detected = True
                    break
            
            # Compare unique value counts for categorical columns
            elif df[col].dtype == 'object':
                unique_diff = abs(input_profile.loc['unique', col] - synthetic_profile.loc['unique', col])
                
                if unique_diff > 0.1 * input_profile.loc['unique', col]:
                    drift_detected = True
                    break

    if not drift_detected:
        break  # Exit loop if data is aligned

# Save final synthetic data
synthetic_df.to_csv("synthetic_data.csv", index=False)
print("Final synthetic data saved as synthetic_data.csv")